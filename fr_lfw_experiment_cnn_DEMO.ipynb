{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Br-alexis73/Face_recognition/blob/master/fr_lfw_experiment_cnn_DEMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7JnxKvP_3KZ",
        "outputId": "47de150d-08da-4d97-ef0d-e52029fa883a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/26922/34595/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240419%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240419T152011Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=b4ec61946419ca8b830a0f4613cac81dffb050d7d712972d73e73a8d24cc40a231fb1a47a2c7bce99a68ff93e9ac40d5a337ede5b14e8940c63ba216337c90b4cc432075b2f24e158971a25f9ecb52e84512e1cdc8473afcdfc20275099542b8cc23208d379bed1a7e644e96a929b7dbb91a7019f5331c94ea9f46d05bdd60badb9169961ed1faa90ae1290e3919c42a5736aa4fd68b941df0dac0e6957e4528a6663da154303292f0925fe7bc92d10ad202845647f7a1eff66f586604bb52c0626b2d95f3daf452d5dae6be3e0f2daf1e3177513be89acda9a7114a083009f77cf36a5edd56f41bb1bf1ba424974542d3b8bd7ac3ec5ab7122a096e033e4df9 to path /kaggle/input/lfw-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'lfw-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F26922%2F34595%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240419%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240419T152011Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3Db4ec61946419ca8b830a0f4613cac81dffb050d7d712972d73e73a8d24cc40a231fb1a47a2c7bce99a68ff93e9ac40d5a337ede5b14e8940c63ba216337c90b4cc432075b2f24e158971a25f9ecb52e84512e1cdc8473afcdfc20275099542b8cc23208d379bed1a7e644e96a929b7dbb91a7019f5331c94ea9f46d05bdd60badb9169961ed1faa90ae1290e3919c42a5736aa4fd68b941df0dac0e6957e4528a6663da154303292f0925fe7bc92d10ad202845647f7a1eff66f586604bb52c0626b2d95f3daf452d5dae6be3e0f2daf1e3177513be89acda9a7114a083009f77cf36a5edd56f41bb1bf1ba424974542d3b8bd7ac3ec5ab7122a096e033e4df9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80GgcNR879Lv",
        "outputId": "360a76a6-a683-462c-cdeb-223527614db1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Import Dependencies"
      ],
      "metadata": {
        "id": "iZK1X-Cx5CEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "gXrdrl1jyva9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Load the LFW-Dataset\n",
        "\n",
        "> Load the dataset from kaggle.\n",
        "\n",
        "> Filter instances of people with at least (N) of instances in their respective class"
      ],
      "metadata": {
        "id": "xLqFguzB2g4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the dataset path\n",
        "dataset_path = '../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'\n",
        "\n",
        "# Generate a list of (name, image count) tuples\n",
        "names_images = []\n",
        "\n",
        "for name in os.listdir(dataset_path):\n",
        "    directory = os.path.join(dataset_path, name)\n",
        "    if os.path.isdir(directory):\n",
        "        images = [i for i in os.listdir(directory) if i.endswith('.jpg')]\n",
        "        image_count = len(images)\n",
        "        # Add to list if there are at least 25 images and store the actual image count\n",
        "        if image_count >= 50:\n",
        "            names_images.append((name, min(image_count, 50)))\n",
        "\n",
        "# Update number_of_people to reflect the actual number of people with at least 25 images\n",
        "number_of_people = len(names_images)\n",
        "print(f\"Number of people with at least 50 images: {number_of_people}\")\n",
        "\n",
        "# Create a DataFrame\n",
        "lfw_allnames = pd.DataFrame(names_images, columns=['name', 'images'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "lfw_csv_path = '../input/lfw-dataset/lfw_allnames.csv'\n",
        "lfw_allnames.to_csv(lfw_csv_path, index=False)\n",
        "\n",
        "print(f\"CSV file created at: {lfw_csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UMXeFqRPyh40",
        "outputId": "fdb08fd1-95c9-456a-b14a-d8e713f7259c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-b1cd01765675>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnames_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Create the LFW-data-refined directory containing the filtered classes"
      ],
      "metadata": {
        "id": "LIzoLpHV3Ouw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a new directory for experiments\n",
        "new_dir_path = '../lfw-data-experiment'\n",
        "\n",
        "# Create the new directory if it doesn't exist\n",
        "if not os.path.exists(new_dir_path):\n",
        "    os.makedirs(new_dir_path)\n",
        "\n",
        "# Move the folders\n",
        "for name, image_count in names_images:\n",
        "    source_folder = os.path.join(dataset_path, name)\n",
        "    destination_folder = os.path.join(new_dir_path, name)\n",
        "\n",
        "    # Check if the destination folder already exists\n",
        "    if os.path.exists(destination_folder):\n",
        "        shutil.rmtree(destination_folder)\n",
        "\n",
        "    # Move the folders\n",
        "    if os.path.exists(source_folder):\n",
        "        shutil.copytree(source_folder, destination_folder)\n",
        "        # If there are more than 50 images, keep the first 50 and delete the rest\n",
        "        images = sorted([i for i in os.listdir(destination_folder) if i.endswith('.jpg')])\n",
        "        for img in images[50:]:  # Delete all images beyond the 25th\n",
        "            os.remove(os.path.join(destination_folder, img))\n",
        "    else:\n",
        "        print(f\"Folder for {name} does not exist in the dataset path.\")\n",
        "\n",
        "print(\"Folders moved successfully.\")"
      ],
      "metadata": {
        "id": "RDmb_LpHy0bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Split Data into training and testing sets.\n",
        "\n",
        "> Here, we can define the image size\n",
        "\n",
        "> And we make sure the imges have their correct labels\n",
        "\n",
        "> Convert labels to one-hot encoded for cross-entropy loss function"
      ],
      "metadata": {
        "id": "tHJah6rN3bI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Read the dataset\n",
        "people_data = os.listdir(new_dir_path)\n",
        "people = []\n",
        "for item in people_data:\n",
        "    person_images = os.listdir(os.path.join(new_dir_path, item))\n",
        "    for person_image in person_images:\n",
        "        people.append((item, os.path.join(new_dir_path, item, person_image)))\n",
        "\n",
        "# Create a DataFrame from the list of tuples\n",
        "people_df = pd.DataFrame(people, columns=['person', 'path'])\n",
        "\n",
        "# Convert labels to one-hot encoded labels\n",
        "label_encoder = LabelEncoder()\n",
        "labels = people_df['person'].values\n",
        "int_encoded = label_encoder.fit_transform(labels)\n",
        "y_onehot = to_categorical(int_encoded)\n",
        "\n",
        "# Correct the size of the images to match the CNN input\n",
        "im_size = 150\n",
        "\n",
        "# Initialize lists to store the images and labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load and preprocess the images\n",
        "for index, row in people_df.iterrows():\n",
        "    img = cv2.imread(row['path'])\n",
        "    img = cv2.resize(img, (im_size, im_size))\n",
        "    images.append(img)\n",
        "    labels.append(row['person'])\n",
        "\n",
        "images = np.array(images)\n",
        "images = images.astype('float32') / 255.0\n",
        "\n",
        "# Shuffle and split the dataset\n",
        "images, y_onehot = shuffle(images, y_onehot, random_state=1)\n",
        "train_x, test_x, train_y_onehot, test_y_onehot = train_test_split(images, y_onehot, test_size=0.3, random_state=415)\n",
        "\n",
        "# Check the shapes again to make sure they match\n",
        "print(\"train_x shape:\", train_x.shape)\n",
        "print(\"train_y_onehot shape:\", train_y_onehot.shape)\n",
        "print(\"test_x shape:\", test_x.shape)\n",
        "print(\"test_y_onehot shape:\", test_y_onehot.shape)"
      ],
      "metadata": {
        "id": "s9rty7ouzGFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Check the shape of the data"
      ],
      "metadata": {
        "id": "iAu-iMCE4VZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame from the list of tuples\n",
        "people_df = pd.DataFrame(people, columns=['person', 'path'])\n",
        "\n",
        "# Count the number of samples for each person\n",
        "person_count = people_df['person'].value_counts()\n",
        "\n",
        "print(\"Total number of images of people in the dataset: \", len(people_df))\n",
        "print(\"Samples in each category: \")\n",
        "print(person_count)\n"
      ],
      "metadata": {
        "id": "fGKfFvTIAGHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explore the data"
      ],
      "metadata": {
        "id": "lQCvA2UA4ye2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "im = Image.open(\"../input/lfw-dataset/lfw-deepfunneled/lfw-deepfunneled/\" + str(lfw_train.image_path[0]))\n",
        "plt.imshow(im)"
      ],
      "metadata": {
        "id": "Ert6ZmVl41h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Model Architecture"
      ],
      "metadata": {
        "id": "mcIPL21vkcR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(labels))\n",
        "# im_shape=(im_size, im_size, 3)"
      ],
      "metadata": {
        "id": "QXctnMYZ6naS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(im_size, im_size, 3)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2, 2),\n",
        "\n",
        "    # Second convolutional layer\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Third convolutional layer\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Flatten the results to feed into a dense layer\n",
        "    Flatten(),\n",
        "\n",
        "    # 256 neurons in the fully connected layer\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.5),  # Dropout for regularization\n",
        "\n",
        "    # Output layer with one neuron per class\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "J8DDI8du_5y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_datagen = ImageDataGenerator(\n",
        "#     rotation_range=20,\n",
        "#     width_shift_range=0.2,\n",
        "#     height_shift_range=0.2,\n",
        "#     shear_range=0.2,\n",
        "#     zoom_range=0.2,\n",
        "#     horizontal_flip=True,\n",
        "#     fill_mode='nearest'\n",
        "# )\n",
        "# train_datagen.fit(train_x)"
      ],
      "metadata": {
        "id": "MMOo9MsVoo9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# history = alexnet.fit(\n",
        "#     train_datagen.flow(train_x, train_y_onehot, batch_size=32),\n",
        "#     epochs=10,\n",
        "#     validation_data=(test_x, test_y_onehot),\n",
        "#     steps_per_epoch=len(train_x) // 32  # This ensures that each epoch uses all data\n",
        "# )\n"
      ],
      "metadata": {
        "id": "be3gLPATozEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_x,\n",
        "    train_y_onehot,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(test_x, test_y_onehot)\n",
        ")"
      ],
      "metadata": {
        "id": "HovHemkUq551"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])  # Now this line is active\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])  # And this line is active\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GmzydI_RpCZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import load_model  # if you have a model to load, otherwise import your CNN architecture\n",
        "\n",
        "# Assuming your CNN has been trained and you have the model loaded\n",
        "# model = load_model('your_model.h5')  # Load your trained model\n",
        "\n",
        "# Generate predictions\n",
        "test_y_pred = model.predict(test_x)\n",
        "test_y_pred_classes = np.argmax(test_y_pred, axis=1)\n",
        "test_y_true = np.argmax(test_y_onehot, axis=1)\n",
        "\n",
        "# Print the confusion matrix\n",
        "conf_matrix = confusion_matrix(test_y_true, test_y_pred_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(test_y_true, test_y_pred_classes, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "id": "IUvl_6c-pHwN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}